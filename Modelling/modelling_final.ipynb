{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(23)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(980, 21)\n"
     ]
    }
   ],
   "source": [
    "mobile_modelling = pd.read_csv('../Data/Data_modelling/mobile_modelling.csv')\n",
    "\n",
    "X = mobile_modelling.iloc[:, 0:-1]\n",
    "y = mobile_modelling.iloc[:, -1]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.3, random_state=42\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_val, y_val, stratify=y_val, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "mobile_df = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "print(mobile_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/d1/hw8k8s1x019_54t0zwhhcrxr0000gp/T/ipykernel_43949/3703627799.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdis_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmobile_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1300x1300 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r = 6\n",
    "c = 4\n",
    "\n",
    "plt.figure(figsize=(13, 13))\n",
    "\n",
    "for i, column in enumerate(train_df.columns):\n",
    "    plt.subplot(r, c, i+1)\n",
    "    dis_dist = sns.distplot(mobile_df[column], bins=20)\n",
    "    dis_dist.set_title(f'Distribution of variable {column}')  \n",
    "\n",
    "plt.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't have a problem with missing values, but we have 2 columns in which we have records with the value of 0, what doesn't make sense:\n",
    "\n",
    "The first one is **px_height**. There is 1 record with the value of 0. So we decided to remove it from our dataset.\n",
    "\n",
    "The second one is **sc_w**. In this case we have 124 records with a value of 0. Removing this amount of records could have an influence on our data and predictions. This is why we decided to try to replace missing values with a mean value from this column in dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "px_height with value of 0:\n",
      "1\n",
      "sc_w with value of 0:\n",
      "94\n"
     ]
    }
   ],
   "source": [
    "print(\"px_height with value of 0:\")\n",
    "print((mobile_df['px_height'] == 0).sum())\n",
    "\n",
    "print(\"sc_w with value of 0:\")\n",
    "print((mobile_df['sc_w'] == 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sc_w = mobile_df[mobile_df['sc_w'] != 0]['sc_w'].mean()\n",
    "mobile_df['sc_w'] = mobile_df['sc_w'].replace(0, mean_sc_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **encoding categorical variables**\n",
    "\n",
    "    In our dataset we don't have any categorical variables that need encoding.\n",
    "- **transforming variables**\n",
    "\n",
    "    In our opinion, there is no need to transform any of the variables.\n",
    "- **scaling/standarisation variables**\n",
    "\n",
    "    SPRAWDZIÄ† DLA JAKICH MODELI MA SENS A DLA JAKICH NIE\n",
    "- **outliers**\n",
    "\n",
    "    After removing missing values, we don't observe any outliers in our dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preliminary modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dummy clasifier\n",
    "- Decision Tree Classifier\n",
    "- Logistic Regression\n",
    "- SVC\n",
    "- Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = mobile_df.iloc[:, 0:-1]\n",
    "y_train = mobile_df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ram              0.467112\n",
       "battery_power    0.076026\n",
       "px_width         0.057708\n",
       "px_height        0.055458\n",
       "mobile_wt        0.039427\n",
       "int_memory       0.037880\n",
       "talk_time        0.032190\n",
       "pc               0.030592\n",
       "sc_w             0.029553\n",
       "clock_speed      0.028856\n",
       "sc_h             0.028498\n",
       "m_dep            0.026579\n",
       "n_cores          0.024210\n",
       "fc               0.023903\n",
       "touch_screen     0.008145\n",
       "blue             0.007236\n",
       "dual_sim         0.007207\n",
       "four_g           0.007192\n",
       "wifi             0.006383\n",
       "three_g          0.005847\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X, y)\n",
    "importances = model.feature_importances_\n",
    "features = X.columns\n",
    "forest_importances = pd.Series(importances, index=features).sort_values(ascending=False)\n",
    "forest_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After checking the importance of all the features, we will test models without taking some of the features into consideration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more than 0.02\n",
    "columns_to_drop_1 = ['touch_screen', 'blue', 'dual_sim', 'four_g', 'wifi', 'three_g']\n",
    "X_train_1 = X_train.drop(columns=columns_to_drop_1)\n",
    "X_val_1 = X_val.drop(columns=columns_to_drop_1)\n",
    "\n",
    "# more than 0.05\n",
    "columns_to_drop_2 = ['touch_screen', 'blue', 'dual_sim', 'four_g', 'wifi', 'three_g', 'fc', 'n_cores', 'm_dep', 'sc_h', 'clock_speed', 'sc_w', 'pc', 'talk_time', 'int_memory', 'mobile_wt']\n",
    "X_train_2 = X_train.drop(columns=columns_to_drop_2)\n",
    "X_val_2 = X_val.drop(columns=columns_to_drop_2)\n",
    "\n",
    "# just RAM and battery power\n",
    "X_train_3 = X_train[['ram', 'battery_power']]\n",
    "X_val_3 = X_val[['ram', 'battery_power']]\n",
    "\n",
    "# more than 0.032\n",
    "columns_to_drop_4 = ['touch_screen', 'blue', 'dual_sim', 'four_g', 'wifi', 'three_g', 'fc', 'n_cores', 'm_dep', 'sc_h', 'clock_speed', 'sc_w', 'pc', 'talk_time']\n",
    "X_train_4 = X_train.drop(columns=columns_to_drop_4)\n",
    "X_val_4 = X_val.drop(columns=columns_to_drop_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standarisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also analyse some of the models with using 2 types of dataset transformations:\n",
    "- Standarisation\n",
    "- Box Cox transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.fit_transform(X_val)\n",
    "\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_val_scaled = pd.DataFrame(X_val_scaled, columns=X_val.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Clasifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most_frequent:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.21      0.21        73\n",
      "           1       0.22      0.22      0.22        74\n",
      "           2       0.20      0.22      0.21        73\n",
      "           3       0.29      0.28      0.29        74\n",
      "\n",
      "    accuracy                           0.23       294\n",
      "   macro avg       0.23      0.23      0.23       294\n",
      "weighted avg       0.23      0.23      0.23       294\n",
      "\n",
      "stratified:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.26      0.28        73\n",
      "           1       0.33      0.28      0.30        74\n",
      "           2       0.31      0.33      0.32        73\n",
      "           3       0.24      0.30      0.27        74\n",
      "\n",
      "    accuracy                           0.29       294\n",
      "   macro avg       0.30      0.29      0.29       294\n",
      "weighted avg       0.30      0.29      0.29       294\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "dc = DummyClassifier(strategy='uniform')\n",
    "dc.fit(X_train,y_train)\n",
    "y_pred = dc.predict(X_val)\n",
    "print('most_frequent:')\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "dc = DummyClassifier(strategy='stratified')\n",
    "dc.fit(X_train,y_train)\n",
    "y_pred = dc.predict(X_val)\n",
    "print('stratified:')\n",
    "print(classification_report(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can observe the accuracy of this model is pretty low, so we decided not to check if any further changes will affect it since we believe we will not be able to achieve satisfactory results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# all\n",
    "model = LogisticRegression(multi_class=\"ovr\")\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = dc.predict(X_val)\n",
    "\n",
    "print('Result for all columns:')\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "# all standarasied\n",
    "model = LogisticRegression(multi_class=\"ovr\")\n",
    "model.fit(X_train_scaled, y_train)\n",
    "y_pred = dc.predict(X_val_scaled)\n",
    "\n",
    "print('Result for all columns, standaraised:')\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "# over 0.02\n",
    "model.fit(X_train_1, y_train)\n",
    "y_pred_1 = dc.predict(X_val_1)\n",
    "\n",
    "print('Result for features with importance greater than 0.02:')\n",
    "print(classification_report(y_val, y_pred_1))\n",
    "\n",
    "# over 0.032\n",
    "model.fit(X_train_4, y_train)\n",
    "y_pred_4 = dc.predict(X_val_2)\n",
    "\n",
    "print('Result for features with importance greater than 0.032:')\n",
    "print(classification_report(y_val, y_pred_4))\n",
    "\n",
    "# over 0.05\n",
    "model.fit(X_train_2, y_train)\n",
    "y_pred_2 = dc.predict(X_val_2)\n",
    "\n",
    "print('Result for features with importance greater than 0.05:')\n",
    "print(classification_report(y_val, y_pred_2))\n",
    "\n",
    "# just ram and battery\n",
    "model.fit(X_train_3, y_train)\n",
    "y_pred_3 = dc.predict(X_val_3)\n",
    "\n",
    "print('Result just for RAM an battery power:')\n",
    "print(classification_report(y_val, y_pred_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case results are also not satisfactory. The best score is obtained when considering all features from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for all columns:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.89      0.93        73\n",
      "           1       0.74      0.84      0.78        74\n",
      "           2       0.76      0.73      0.74        73\n",
      "           3       0.89      0.88      0.88        74\n",
      "\n",
      "    accuracy                           0.83       294\n",
      "   macro avg       0.84      0.83      0.83       294\n",
      "weighted avg       0.84      0.83      0.83       294\n",
      "\n",
      "Result for all columns, standaraised:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.91        73\n",
      "           1       0.75      0.72      0.73        74\n",
      "           2       0.74      0.73      0.73        73\n",
      "           3       0.88      0.88      0.88        74\n",
      "\n",
      "    accuracy                           0.81       294\n",
      "   macro avg       0.81      0.81      0.81       294\n",
      "weighted avg       0.81      0.81      0.81       294\n",
      "\n",
      "Result for features with importance greater than 0.02:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.86      0.90        73\n",
      "           1       0.72      0.78      0.75        74\n",
      "           2       0.73      0.74      0.73        73\n",
      "           3       0.90      0.88      0.89        74\n",
      "\n",
      "    accuracy                           0.82       294\n",
      "   macro avg       0.82      0.82      0.82       294\n",
      "weighted avg       0.82      0.82      0.82       294\n",
      "\n",
      "Result for features with importance greater than 0.032:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.89      0.93        73\n",
      "           1       0.78      0.86      0.82        74\n",
      "           2       0.77      0.77      0.77        73\n",
      "           3       0.90      0.88      0.89        74\n",
      "\n",
      "    accuracy                           0.85       294\n",
      "   macro avg       0.86      0.85      0.85       294\n",
      "weighted avg       0.86      0.85      0.85       294\n",
      "\n",
      "Result for features with importance greater than 0.05:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93        73\n",
      "           1       0.81      0.85      0.83        74\n",
      "           2       0.79      0.78      0.79        73\n",
      "           3       0.90      0.89      0.90        74\n",
      "\n",
      "    accuracy                           0.86       294\n",
      "   macro avg       0.86      0.86      0.86       294\n",
      "weighted avg       0.86      0.86      0.86       294\n",
      "\n",
      "Result just for RAM an battery power:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.78      0.83        73\n",
      "           1       0.69      0.72      0.70        74\n",
      "           2       0.66      0.68      0.67        73\n",
      "           3       0.80      0.82      0.81        74\n",
      "\n",
      "    accuracy                           0.75       294\n",
      "   macro avg       0.76      0.75      0.75       294\n",
      "weighted avg       0.76      0.75      0.75       294\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier,plot_tree #export_graphviz\n",
    "\n",
    "# all\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X_train,y_train)\n",
    "y_pred = tree.predict(X_val)\n",
    "print('Result for all columns:')\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "# all standarasied\n",
    "tree.fit(X_train_scaled, y_train)\n",
    "y_pred_5= tree.predict(X_val_scaled)\n",
    "print('Result for all columns, standaraised:')\n",
    "print(classification_report(y_val, y_pred_5))\n",
    "\n",
    "# over 0.02\n",
    "tree.fit(X_train_1,y_train)\n",
    "y_pred_1= tree.predict(X_val_1)\n",
    "print('Result for features with importance greater than 0.02:')\n",
    "print(classification_report(y_val, y_pred_1))\n",
    "\n",
    "# over 0.032\n",
    "tree.fit(X_train_4,y_train)\n",
    "y_pred_4= tree.predict(X_val_4)\n",
    "print('Result for features with importance greater than 0.032:')\n",
    "print(classification_report(y_val, y_pred_4))\n",
    "\n",
    "# over 0.05\n",
    "tree.fit(X_train_2,y_train)\n",
    "y_pred_2= tree.predict(X_val_2)\n",
    "print('Result for features with importance greater than 0.05:')\n",
    "print(classification_report(y_val, y_pred_2))\n",
    "\n",
    "# just ram and battery power\n",
    "tree.fit(X_train_3, y_train)\n",
    "y_pred_3= tree.predict(X_val_3)\n",
    "print('Result just for RAM an battery power:')\n",
    "print(classification_report(y_val, y_pred_3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
