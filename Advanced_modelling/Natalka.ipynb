{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile_modelling = pd.read_csv('../Data/Data_modelling/mobile_modelling.csv')\n",
    "\n",
    "X = mobile_modelling.iloc[:, 0:-1]\n",
    "y = mobile_modelling.iloc[:, -1]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.3, random_state=42\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_val, y_val, stratify=y_val, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "mobile_df = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# variables with importance of more than 0.02 \n",
    "columns_to_drop_1 = ['touch_screen', 'blue', 'dual_sim', 'four_g', 'wifi', 'three_g']\n",
    "X_train_r = X_train.drop(columns=columns_to_drop_1)\n",
    "X_val_r = X_val.drop(columns=columns_to_drop_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging (Bootstrap Aggregating)\n",
    "designed to improve the stability and accuracy of machine learning algorithms used in statistical classification and regression. It decreases the variance and helps to avoid overfitting. It is usually applied to decision tree methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we're testing Bagging method with two tree models - DecisionTreeClassifier and RandomForestClassifier\n",
    "\n",
    "in 2 variants: with all the columns and with columns having importance greater than 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging with DecisionTreeClassifier - all columns\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94        73\n",
      "           1       0.78      0.84      0.81        74\n",
      "           2       0.70      0.79      0.74        73\n",
      "           3       0.94      0.78      0.85        74\n",
      "\n",
      "    accuracy                           0.83       294\n",
      "   macro avg       0.84      0.83      0.84       294\n",
      "weighted avg       0.84      0.83      0.84       294\n",
      "\n",
      "Bagging with DecisionTreeClassifier - important columns\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.92        73\n",
      "           1       0.79      0.81      0.80        74\n",
      "           2       0.72      0.82      0.77        73\n",
      "           3       0.94      0.81      0.87        74\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.84      0.84      0.84       294\n",
      "weighted avg       0.84      0.84      0.84       294\n",
      "\n",
      "\n",
      "Bagging with RandomForestClassifier - all columns\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93        73\n",
      "           1       0.75      0.77      0.76        74\n",
      "           2       0.72      0.74      0.73        73\n",
      "           3       0.93      0.86      0.90        74\n",
      "\n",
      "    accuracy                           0.83       294\n",
      "   macro avg       0.83      0.83      0.83       294\n",
      "weighted avg       0.83      0.83      0.83       294\n",
      "\n",
      "\n",
      "Bagging with RandomForestClassifier - important columns\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93        73\n",
      "           1       0.77      0.80      0.78        74\n",
      "           2       0.74      0.77      0.75        73\n",
      "           3       0.94      0.86      0.90        74\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.84      0.84      0.84       294\n",
      "weighted avg       0.84      0.84      0.84       294\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating 2 models\n",
    "model_dt = DecisionTreeClassifier(random_state=42)\n",
    "model_rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Bagging for first model\n",
    "bagging_model_dt = BaggingClassifier(estimator=model_dt, n_estimators=10, random_state=42)\n",
    "bagging_model_dt.fit(X_train, y_train)\n",
    "\n",
    "bagging_model_dt_r = BaggingClassifier(estimator=model_dt, n_estimators=10, random_state=42)\n",
    "bagging_model_dt_r.fit(X_train_r, y_train)\n",
    "\n",
    "# Bagging for second model\n",
    "bagging_model_rf = BaggingClassifier(estimator=model_rf, n_estimators=10, random_state=42)\n",
    "bagging_model_rf.fit(X_train, y_train)\n",
    "\n",
    "bagging_model_rf_r = BaggingClassifier(estimator=model_rf, n_estimators=10, random_state=42)\n",
    "bagging_model_rf_r.fit(X_train_r, y_train)\n",
    "\n",
    "# Checking predictions on validation datasets\n",
    "predictions_model_dt = bagging_model_dt.predict(X_val)\n",
    "predictions_model_dt_r = bagging_model_dt_r.predict(X_val_r)\n",
    "\n",
    "predictions_model_rf = bagging_model_rf.predict(X_val)\n",
    "predictions_model_rf_r = bagging_model_rf_r.predict(X_val_r)\n",
    "\n",
    "# Printing classification report\n",
    "print(\"Bagging with DecisionTreeClassifier - all columns\")\n",
    "print(classification_report(y_val, predictions_model_dt))\n",
    "\n",
    "print(\"Bagging with DecisionTreeClassifier - important columns\")\n",
    "print(classification_report(y_val, predictions_model_dt_r))\n",
    "\n",
    "print(\"\\nBagging with RandomForestClassifier - all columns\")\n",
    "print(classification_report(y_val, predictions_model_rf))\n",
    "\n",
    "print(\"\\nBagging with RandomForestClassifier - important columns\")\n",
    "print(classification_report(y_val, predictions_model_rf_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting\n",
    "we're checking Boosting method with:\n",
    "    AdaBoost\n",
    "    XGBoost\n",
    "    CatBoost"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
